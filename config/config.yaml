batch_size: 2
tensor_cut: 3200000
max_epoch: 10000 
save_folder: './save/'
save_location: '${save_folder}batch${batch_size}_cut${tensor_cut}_lr${lr}_' 
train_csv_path: '/mnt/lustre/sjtu/home/zkn02/EnCodec_Trainer/sub_librispeech_train100h.csv'
lr: 3e-4
disc_lr: 3e-4
seed: 3401
target_bandwidths: [1.5, 3., 6, 12., 24.]
sample_rate: 24_000
channels: 1
log_interval: 1
step_size: 1000
disc_step_size: 1000
gamma: 0.1
disc_gamma: 0.1
fixed_length: 0
data_parallel: True
find_unused_parameters: False
